{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle competition\n",
    "\n",
    "Label satellite image chips with atmospheric conditions and various classes of land cover/land use. Resulting algorithms will help the global community better understand where, how, and why deforestation happens all over the world - and ultimately how to respond\n",
    "\n",
    "\n",
    "#### What the data looks like ? \n",
    "Train-jpg: 40K+ satelite photos <br>\n",
    "train_v2: (image_name, tags) Unique tags 449 <br>\n",
    "So this is a multilabel image classification problem\n",
    "\n",
    "#### Challenge\n",
    "Unlike dog and cat image recognition, the image set are very similar in colors\n",
    "```terminal\n",
    "source activate tensorflow_p36\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi CUDA monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math, glob, os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tags 449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_path = '/home/ubuntu/.kaggle/competitions/planet-understanding-the-amazon-from-space/'\n",
    "# kaggle_path = '/Users/mumuxi/.kaggle/competitions/planet-understanding-the-amazon-from-space/'\n",
    "labels = pd.read_csv(kaggle_path+'train_v2.csv')\n",
    "print ('Number of unique tags',len(labels['tags'].unique()))\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation():\n",
    "#     df = pd.read_csv(kaggle_path+'test_v2_file_mapping.csv')\n",
    "#     return df.head(3)\n",
    "# validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_photos(rows,columns):\n",
    "    fig=plt.figure(figsize=(15, 15))\n",
    "    for i in range(1, columns*rows +1):\n",
    "        path = kaggle_path+f'train-jpg/train_{i}.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        ax = fig.add_subplot(rows, columns, i)\n",
    "        ax.set_xlabel(labels.tags[i])\n",
    "        plt.imshow(img)\n",
    "# example_photos(rows=4,columns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation - F2 SCORE\n",
    "F2 is used to evaluate how good the model is and has a formula given below\n",
    "\n",
    "$F_{2} = (1+β^{2})\\frac{pr}{β^{2}p+r}$\n",
    "\n",
    "\n",
    ",where *p* is precision, *r* is recall and β=2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tags EDA\n",
    "- Most tags contains primary\n",
    "- Clear has strong negative correlations with cloudy, haze, partly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.backend as K\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tags(tokenizer):\n",
    "    tags = tokenizer.word_docs\n",
    "    fig  = plt.figure(figsize=(10, 6))\n",
    "    tags = dict(sorted(tags.items(), key=lambda x: (-x[1], x[0])))\n",
    "    plt.bar(tags.keys(), np.array(list(tags.values()))/sum(list(tags.values())), 1, color='lightblue')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Tags distribution')\n",
    "\n",
    "def img_multilabel(tokenizer,texts,plot=True):\n",
    "    M  = tokenizer.texts_to_matrix(texts, mode='count')\n",
    "    df = pd.DataFrame(data=M,columns=['0']+list(tokenizer.word_index.keys()))\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[1:-1]\n",
    "    df = df[cols]\n",
    "    if plot:\n",
    "        corr = df.corr()\n",
    "        fig=plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr)\n",
    "    return df\n",
    "\n",
    "def get_multitags():\n",
    "    texts = labels.tags.tolist()\n",
    "    tokenizer = Tokenizer(filters = '\"#()*+,-./:;<=>?@[\\]^`{|}~')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "#     plot_tags(tokenizer)\n",
    "    return img_multilabel(tokenizer,texts,False)\n",
    "\n",
    "df_label = get_multitags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haze vs clear  2697  :  28431\n"
     ]
    }
   ],
   "source": [
    "haze_id = df_label.loc[df_label['haze']==1].index.values\n",
    "clear_id = df_label.loc[df_label['clear']==1].index.values\n",
    "print ('haze vs clear ',len(haze_id),' : ',len(clear_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Image\n",
    "#### 1. Calculate haze degree\n",
    "Source: [Detecting Foggy Images and Estimating the Haze Degree Factor](https://www.omicsonline.org/open-access/detecting-foggy-images-and-estimating-the-haze-degree-factor-jcsb.1000226.pdf)\n",
    "\n",
    "Define haze degree as w, where w is a number between (0,1). Smaller w indicates a clearer image while haze images have greater w.  For example, w greater than 0.7 means 80%-100% of the image area is hazed.\n",
    "\n",
    "#### 2. Dehaze images\n",
    "Source: [Single Image Haze Removal Using Dark Channel Prior](https://www.robots.ox.ac.uk/~vgg/rg/papers/hazeremoval.pdf)\n",
    "\n",
    "The following formula is widely used to describe the formation of a haze image\n",
    "\n",
    "$I(x) = J(x)t(x) + A(1-t(x))$\n",
    "\n",
    "where *I* is the observed intensity, *J* represents the original haze-free image to be recovered, *A* is the global atmospheric light, and *t* is an exponential decay distribution .\n",
    "\n",
    "The aim is to recover *J* from *I*. We can achieve that by tuning *t*, as *t* has a formula of\n",
    "\n",
    "$t(x) = 1- w\\times min[min(\\frac{I_{c}(y)}{A^{c}})]$\n",
    ",where *w* is weight coefficient, *c* is the dark channel color (darkest channel of RGB channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Single image dehazing.\"\"\"\n",
    "class Channel_value:\n",
    "    val = -1.0\n",
    "    intensity = -1.0\n",
    "\n",
    "def find_intensity_of_atmospheric_light(img, gray):\n",
    "    \"\"\"return Atomospheric light A \"\"\"\n",
    "    # pick top 0.1% brightest pixels in the dark channel ~ most hazeopaque\n",
    "    top_num = int(img.shape[0] * img.shape[1] * 0.001)\n",
    "    toplist = [Channel_value()] * top_num \n",
    "    dark_channel = find_dark_channel(img)\n",
    "    for y in range(img.shape[0]):\n",
    "        for x in range(img.shape[1]):\n",
    "            val = img.item(y, x, dark_channel)\n",
    "            intensity = gray.item(y, x)\n",
    "            for t in toplist:  # create 65 different channels \n",
    "                if t.val < val or (t.val == val and t.intensity < intensity):\n",
    "                    t.val = val\n",
    "                    t.intensity = intensity\n",
    "                    break\n",
    "    max_channel = Channel_value()\n",
    "    for t in toplist:\n",
    "        if t.intensity > max_channel.intensity:\n",
    "            max_channel = t\n",
    "    return max_channel.intensity\n",
    "\n",
    "def find_dark_channel(img): #get darkest RBG channel\n",
    "    return np.unravel_index(np.argmin(img), img.shape)[2]\n",
    "\n",
    "def clamp(minimum, x, maximum):\n",
    "    return max(minimum, min(x, maximum))\n",
    "\n",
    "def dehaze_function(img, light_intensity, windowSize, t0, w):\n",
    "    size = (img.shape[0], img.shape[1])\n",
    "    outimg = np.zeros(img.shape, img.dtype)\n",
    "    for y in range(size[0]):\n",
    "        for x in range(size[1]):\n",
    "            x_low = max(x-(windowSize//2), 0)\n",
    "            y_low = max(y-(windowSize//2), 0)\n",
    "            x_high = min(x+(windowSize//2), size[1])\n",
    "            y_high = min(y+(windowSize//2), size[0])\n",
    "            sliceimg = img[y_low:y_high, x_low:x_high]\n",
    "            dark_channel = find_dark_channel(sliceimg)\n",
    "            t = 1.0 - (w * img.item(y, x, dark_channel) / light_intensity)\n",
    "            outimg.itemset((y,x,0), clamp(0, ((img.item(y,x,0) - light_intensity) / max(t, t0) + light_intensity), 255))\n",
    "            outimg.itemset((y,x,1), clamp(0, ((img.item(y,x,1) - light_intensity) / max(t, t0) + light_intensity), 255))\n",
    "            outimg.itemset((y,x,2), clamp(0, ((img.item(y,x,2) - light_intensity) / max(t, t0) + light_intensity), 255))\n",
    "    return outimg\n",
    "\n",
    "\n",
    "def dehaze_image(path,w = 0.95, t0 = 0.55):\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #image to gray scale\n",
    "    light_intensity = find_intensity_of_atmospheric_light(img, gray)\n",
    "    outimg = dehaze_function(img, light_intensity, 20, t0, w)\n",
    "    return outimg\n",
    "\n",
    "def example_photo_no(image_id,train=True):\n",
    "    if train:\n",
    "        path = kaggle_path+f'train-jpg/train_{image_id}.jpg'\n",
    "    else:\n",
    "        path = kaggle_path+f'test-jpg/test_{image_id}.jpg'\n",
    "    img = cv2.imread(path)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def intensity_plot(path):\n",
    "    img = cv2.imread(path)\n",
    "    color = ('b','g','r')\n",
    "    histr = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    plt.plot(histr)\n",
    "## %%%%%%%%      GRB PLOT   %%%%%%%%\n",
    "#     for i,col in enumerate(color):\n",
    "#         histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "#         plt.plot(histr,color = col)\n",
    "#         plt.xlim([0,256])\n",
    "# ##  %%%%%%%     CDF plot    %%%%%%%%\n",
    "#     values, bins = np.histogram(img.ravel(),256,[0,256],normed=True)\n",
    "#     cum = np.cumsum(values)\n",
    "#     plt.plot(bins[:-1],cum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "miu, v, sigma = 5.1,2.9,.2461\n",
    "def calculate_haziness(image_id):\n",
    "    path = kaggle_path+f'train-jpg/train_{image_id}.jpg'\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #image to gray scale\n",
    "    A = find_intensity_of_atmospheric_light(img, gray)\n",
    "    D = img.min(2).sum()/(img.shape[0]*img.shape[1])\n",
    "    B = img.max(2).sum()/(img.shape[0]*img.shape[1])\n",
    "    C = B - D\n",
    "    w = math.e**(-0.5*(miu*(A-D)/A+v*C/A))\n",
    "    return (image_id,w)\n",
    "\n",
    "def compare_photos(image_id):\n",
    "    path = kaggle_path+f'train-jpg/train_{image_id}.jpg'\n",
    "    fig=plt.figure(figsize=(5, 8))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    dehazed_img = dehaze_image(path)\n",
    "    plt.imshow(dehazed_img)\n",
    "    fig.add_subplot(212,sharex=ax1)\n",
    "    example_photo_no(image_id)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_haziness(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('top picture is haze-free image, bottom one is the original picture')\n",
    "compare_photos(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression \n",
    "- Distiguish haze | clear label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Neural Network vanilla model\n",
    "- Importing the Keras libraries and packages\n",
    "- Sequential:<br> initialise model as a sequential network. There are two basic ways of initialising a neural network, either by a sequence of layers or as a graph\n",
    "\n",
    "#### 1.1 Load Data\n",
    "\n",
    "#### 1.2 Model Work Flow\n",
    "1. **Conv2D** \n",
    "    - Images => 2 D arrays\n",
    "    - Videos => Convolution 3-D \n",
    "    \n",
    "    \n",
    "2. **MaxPooling2D**:<br> The primary aim of a pooling operation is to reduce the size of the images. Different types of pooling operations like Min Pooling, Mean Pooling, etc. Here in MaxPooling we need the maximum value pixel from the respective region of interest.\n",
    "\n",
    "\n",
    "3. **Flatten**:<br> Flattening is the process of converting all the resultant 2 dimensional arrays into a continuous vector.\n",
    "\n",
    "\n",
    "4. **Dense** \n",
    "    - units: no nodes in the hidden layer\n",
    "5. **compile**\n",
    "    - Optimizer:  stochastic gradient descent algorithm\n",
    "    - Loss: loss function\n",
    "    - Metrics: performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout,BatchNormalization\n",
    "from keras.initializers import glorot_normal, RandomNormal, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(train_ids,test_ids):\n",
    "    read = lambda i: cv2.imread(kaggle_path+f'train-jpg/train_{i}.jpg')\n",
    "    train_array = np.array(list(map(read,train_ids)))\n",
    "    test_array = np.array(list(map(read,test_ids)))\n",
    "    return train_array,test_array\n",
    "\n",
    "def load_data():\n",
    "    y_train, y_test = train_test_split(df_label, test_size=0.3,random_state=144)\n",
    "    X_train, X_test = load_train_test(y_train.index.tolist(),y_test.index.tolist())\n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test = load_data()\n",
    "print (X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_layers2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),padding='same',activation = 'elu', input_shape = (256, 256, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3),padding='same',activation = 'elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3),padding='same',activation = 'elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(17))\n",
    "    model.add(Activation('sigmoid'))\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true,y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true,y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "    \n",
    "def F2_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return (1+4)*precision*recall/(4*precision+recall)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "#     model = create_model()\n",
    "    model = build_layers2()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
    "                  metrics = ['accuracy',F2_score,precision,recall])\n",
    "    return model\n",
    "\n",
    "def train_model():\n",
    "    model = get_model()\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=50)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss: %.3f  accuracy: %.3f F2 score: %.3f.' %(score[0],score[1],score[2]))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model()\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "28335/28335 [==============================] - 69s 2ms/step - loss: 0.3379 - acc: 0.8933 - F2_score: 0.6307 - precision: 0.7655 - recall: 0.6102\n",
      "Test loss: 0.228  accuracy: 0.912 F2 score: 0.629.\n"
     ]
    }
   ],
   "source": [
    "model2 = train_model()\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Implementation\n",
    "Build different models and test\n",
    "\n",
    "F2 | prec  |  recall\n",
    "_________________________\n",
    "0.45 | 0.00 | 0.00 | model 1 - single layer \n",
    "\n",
    "0.70 | 0.47 | 0.75 | model 2 Test F2: 0.754 - multi layers\n",
    "\n",
    "0.00 | 0.00 | 0.00 | model 3 - haze free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1768438e-05, 9.9978489e-01, 9.9789989e-01, 6.1102025e-02,\n",
       "       2.8259799e-02, 7.5224273e-02, 3.0304273e-03, 5.3825055e-04,\n",
       "       1.9690478e-03, 3.4824154e-08, 2.1964509e-06, 6.0668372e-04,\n",
       "       2.4181818e-04, 9.1164708e-05, 2.1753232e-03, 3.7091646e-05,\n",
       "       3.8241674e-06], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_test_labels(model):\n",
    "    N = 5000\n",
    "    y_pred = model.predict(X_train[0:N])\n",
    "    primary_train = y_pred[:,2]\n",
    "    primary_test = y_train['clear'][0:N].values\n",
    "    plt.scatter(primary_train,primary_test)\n",
    "    plt.show()\n",
    "predict_test_labels(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of images detected: 0, with acc of 0.000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>primary</th>\n",
       "      <th>clear</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>road</th>\n",
       "      <th>water</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>habitation</th>\n",
       "      <th>haze</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>blooming</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>blow_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19487</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conventional_mine  primary  clear  agriculture  road  water  \\\n",
       "21072                0.0      1.0    1.0          0.0   0.0    0.0   \n",
       "10931                0.0      0.0    1.0          0.0   0.0    0.0   \n",
       "15216                0.0      1.0    1.0          0.0   0.0    0.0   \n",
       "578                  0.0      1.0    1.0          0.0   0.0    0.0   \n",
       "19487                0.0      1.0    1.0          0.0   1.0    1.0   \n",
       "\n",
       "       partly_cloudy  cultivation  habitation  haze  cloudy  bare_ground  \\\n",
       "21072            0.0          0.0         0.0   0.0     0.0          0.0   \n",
       "10931            0.0          0.0         0.0   0.0     0.0          1.0   \n",
       "15216            0.0          0.0         0.0   0.0     0.0          0.0   \n",
       "578              0.0          0.0         0.0   0.0     0.0          0.0   \n",
       "19487            0.0          0.0         0.0   0.0     0.0          0.0   \n",
       "\n",
       "       selective_logging  artisinal_mine  blooming  slash_burn  blow_down  \n",
       "21072                0.0             0.0       0.0         0.0        0.0  \n",
       "10931                0.0             0.0       0.0         0.0        0.0  \n",
       "15216                0.0             0.0       0.0         0.0        0.0  \n",
       "578                  0.0             0.0       0.0         0.0        0.0  \n",
       "19487                0.0             0.0       0.0         0.0        0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix\n",
    "version 1 - single layer\n",
    "```python\n",
    "def build_layers():\n",
    "    \"\"\"32 filters of size 12x12\n",
    "        input image size 256 x 256, 3 for RGB\n",
    "    \"\"\"\n",
    "    no_features = 17\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(12,12), activation = 'relu',input_shape = (256, 256, 3)))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = no_features, activation = 'sigmoid'))\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
