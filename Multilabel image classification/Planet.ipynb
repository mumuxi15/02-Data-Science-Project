{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle competition\n",
    "\n",
    "Label satellite image chips with atmospheric conditions and various classes of land cover/land use. Resulting algorithms will help the global community better understand where, how, and why deforestation happens all over the world - and ultimately how to respond\n",
    "\n",
    "\n",
    "#### What the data looks like ? \n",
    "Train-jpg: 40K+ satelite photos <br>\n",
    "train_v2: (image_name, tags) Unique tags 449 <br>\n",
    "So this is a multilabel image classification problem\n",
    "\n",
    "#### Challenge\n",
    "Unlike dog and cat image recognition, the image set are very similar in colors\n",
    "```terminal\n",
    "nvidia-smi CUDA # monitoring\n",
    "source activate tensorflow_p36\n",
    "```\n",
    "\n",
    "###  Tags EDA\n",
    "- Most tags contains primary\n",
    "- Clear has strong negative correlations with cloudy, haze, partly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from scipy.integrate import cumtrapz\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math, glob, os\n",
    "import operator\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_path = '/home/ubuntu/.kaggle/competitions/planet-understanding-the-amazon-from-space/'\n",
    "# kaggle_path = '/Users/mumuxi/.kaggle/competitions/planet-understanding-the-amazon-from-space/'\n",
    "\n",
    "def plot_tag_distribution(tokenizer):\n",
    "    tags = tokenizer.word_docs\n",
    "    fig  = plt.figure(figsize=(10, 6))\n",
    "    tags = dict(sorted(tags.items(), key=lambda x: (-x[1], x[0])))\n",
    "    plt.bar(tags.keys(), np.array(list(tags.values()))/sum(list(tags.values())), 1, color='lightblue')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Tags distribution')\n",
    "\n",
    "def seperate_multilabel(tokenizer,texts,plot=True):\n",
    "    M  = tokenizer.texts_to_matrix(texts, mode='count')\n",
    "    df = pd.DataFrame(data=M,columns=['0']+list(tokenizer.word_index.keys()))\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[1:-1]\n",
    "    df = df[cols]\n",
    "    if plot:\n",
    "        corr = df.corr()\n",
    "        fig=plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr)\n",
    "    return df\n",
    "\n",
    "def get_multitags():\n",
    "    label = pd.read_csv(kaggle_path+'train_v2.csv')\n",
    "    texts = label.tags.tolist()\n",
    "    tokenizer = Tokenizer(filters = '\"#()*+,-./:;<=>?@[\\]^`{|}~')\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "#     plot_tag_distribution(tokenizer)\n",
    "    return seperate_multilabel(tokenizer,texts,False)\n",
    "\n",
    "df_label = get_multitags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haze_id = df_label.loc[df_label['haze']==1].index.values\n",
    "# clear_id = df_label.loc[df_label['clear']==1].index.values\n",
    "# print ('haze vs clear ',len(haze_id),' : ',len(clear_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_photos(rows,columns):\n",
    "    fig=plt.figure(figsize=(15, 15))\n",
    "    for i in range(1, columns*rows +1):\n",
    "        path = kaggle_path+f'train-jpg/train_{i}.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        ax = fig.add_subplot(rows, columns, i)\n",
    "        ax.set_xlabel(labels.tags[i])\n",
    "        plt.imshow(img)\n",
    "# display_photos(rows=4,columns=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation - F2 SCORE\n",
    "F2 is used to evaluate how good the model is and has a formula given below\n",
    "\n",
    "$F_{2} = (1+β^{2})\\frac{pr}{β^{2}p+r}$\n",
    "\n",
    "\n",
    ",where *p* is precision, *r* is recall and β=2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Data\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12144, 256, 256, 3) (12144, 17)\n"
     ]
    }
   ],
   "source": [
    "def load_train_test(train_ids,test_ids):\n",
    "    read = lambda i: cv2.imread(kaggle_path+f'train-jpg/train_{i}.jpg')\n",
    "    train_array = np.array(list(map(read,train_ids)))\n",
    "    test_array = np.array(list(map(read,test_ids)))\n",
    "    return train_array,test_array\n",
    "\n",
    "def load_data():\n",
    "    y_train, y_test = train_test_split(df_label, test_size=0.3,random_state=144)\n",
    "    X_train, X_test = load_train_test(y_train.index.tolist(),y_test.index.tolist())\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "X_train,y_train,X_test,y_test = load_data()\n",
    "print (X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Image\n",
    "#### 1. Calculate haze degree\n",
    "Source: [Detecting Foggy Images and Estimating the Haze Degree Factor](https://www.omicsonline.org/open-access/detecting-foggy-images-and-estimating-the-haze-degree-factor-jcsb.1000226.pdf)\n",
    "\n",
    "Define haze degree as w, where w is a number between (0,1). Smaller w indicates a clearer image while haze images have greater w.  For example, w greater than 0.7 means 80%-100% of the image area is hazed.\n",
    "\n",
    "#### 2. Dehaze images\n",
    "Source: [Single Image Haze Removal Using Dark Channel Prior](https://www.robots.ox.ac.uk/~vgg/rg/papers/hazeremoval.pdf)\n",
    "\n",
    "The following formula is widely used to describe the formation of a haze image\n",
    "\n",
    "$I(x) = J(x)t(x) + A(1-t(x))$\n",
    "\n",
    "where *I* is the observed intensity, *J* represents the original haze-free image to be recovered, *A* is the global atmospheric light, and *t* is an exponential decay distribution .\n",
    "\n",
    "The aim is to recover *J* from *I*. We can achieve that by tuning *t*, as *t* has a formula of\n",
    "\n",
    "$t(x) = 1- w\\times min[min(\\frac{I_{c}(y)}{A^{c}})]$\n",
    ",where *w* is weight coefficient, *c* is the dark channel color (darkest channel of RGB channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Single image dehazing.\"\"\"\n",
    "class Channel_value:\n",
    "    val = -1.0\n",
    "    intensity = -1.0\n",
    "\n",
    "def find_intensity_of_atmospheric_light(img, gray):\n",
    "    \"\"\"return Atomospheric light A \"\"\"\n",
    "    # pick top 0.1% brightest pixels in the dark channel ~ most hazeopaque\n",
    "    top_num = int(img.shape[0] * img.shape[1] * 0.001)\n",
    "    toplist = [Channel_value()] * top_num \n",
    "    dark_channel = find_dark_channel(img)\n",
    "    for y in range(img.shape[0]):\n",
    "        for x in range(img.shape[1]):\n",
    "            val = img.item(y, x, dark_channel)\n",
    "            intensity = gray.item(y, x)\n",
    "            for t in toplist:  # create 65 different channels \n",
    "                if t.val < val or (t.val == val and t.intensity < intensity):\n",
    "                    t.val = val\n",
    "                    t.intensity = intensity\n",
    "                    break\n",
    "    max_channel = Channel_value()\n",
    "    for t in toplist:\n",
    "        if t.intensity > max_channel.intensity:\n",
    "            max_channel = t\n",
    "    return max_channel.intensity\n",
    "\n",
    "def find_dark_channel(img): #get darkest RBG channel\n",
    "    return np.unravel_index(np.argmin(img), img.shape)[2]\n",
    "\n",
    "def clamp(minimum, x, maximum):\n",
    "    return max(minimum, min(x, maximum))\n",
    "\n",
    "def dehaze_function(img, light_intensity, windowSize, t0, w):\n",
    "    size = (img.shape[0], img.shape[1])\n",
    "    outimg = np.zeros(img.shape, img.dtype)\n",
    "    for y in range(size[0]):\n",
    "        for x in range(size[1]):\n",
    "            x_low = max(x-(windowSize//2), 0)\n",
    "            y_low = max(y-(windowSize//2), 0)\n",
    "            x_high = min(x+(windowSize//2), size[1])\n",
    "            y_high = min(y+(windowSize//2), size[0])\n",
    "            sliceimg = img[y_low:y_high, x_low:x_high]\n",
    "            dark_channel = find_dark_channel(sliceimg)\n",
    "            t = 1.0 - (w * img.item(y, x, dark_channel) / light_intensity)\n",
    "            outimg.itemset((y,x,0), clamp(0, ((img.item(y,x,0) - light_intensity) / max(t, t0) + light_intensity), 255))\n",
    "            outimg.itemset((y,x,1), clamp(0, ((img.item(y,x,1) - light_intensity) / max(t, t0) + light_intensity), 255))\n",
    "            outimg.itemset((y,x,2), clamp(0, ((img.item(y,x,2) - light_intensity) / max(t, t0) + light_intensity), 255))\n",
    "    return outimg\n",
    "\n",
    "\n",
    "def dehaze_image(path,w = 0.95, t0 = 0.55):\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #image to gray scale\n",
    "    light_intensity = find_intensity_of_atmospheric_light(img, gray)\n",
    "    outimg = dehaze_function(img, light_intensity, 20, t0, w)\n",
    "    return outimg\n",
    "\n",
    "#  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "def display_photo_no(image_id,train=True):\n",
    "    if train:\n",
    "        path = kaggle_path+f'train-jpg/train_{image_id}.jpg'\n",
    "    else:\n",
    "        path = kaggle_path+f'test-jpg/test_{image_id}.jpg'\n",
    "    img = cv2.imread(path)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def intensity_plot(path):\n",
    "    img = cv2.imread(path)\n",
    "    color = ('b','g','r')\n",
    "    histr = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    plt.plot(histr)\n",
    "## %%%%%%%%      GRB PLOT   %%%%%%%%\n",
    "#     for i,col in enumerate(color):\n",
    "#         histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "#         plt.plot(histr,color = col)\n",
    "#         plt.xlim([0,256])\n",
    "# ##  %%%%%%%     CDF plot    %%%%%%%%\n",
    "#     values, bins = np.histogram(img.ravel(),256,[0,256],normed=True)\n",
    "#     cum = np.cumsum(values)\n",
    "#     plt.plot(bins[:-1],cum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "miu, v, sigma = 5.1,2.9,.2461\n",
    "def calculate_haziness(img_id):\n",
    "    path = kaggle_path+f'train-jpg/train_{img_id}.jpg'\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #image to gray scale\n",
    "    A = find_intensity_of_atmospheric_light(img, gray)\n",
    "    D = img.min(2).sum()/(img.shape[0]*img.shape[1])\n",
    "    B = img.max(2).sum()/(img.shape[0]*img.shape[1])\n",
    "    C = B - D\n",
    "    w = math.e**(-0.5*(miu*(A-D)/A+v*C/A))\n",
    "    return (img_id,w)\n",
    "\n",
    "def compare_photos(image_id):\n",
    "    path = kaggle_path+f'train-jpg/train_{image_id}.jpg'\n",
    "    fig=plt.figure(figsize=(5, 8))\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    dehazed_img = dehaze_image(path)\n",
    "    plt.imshow(dehazed_img)\n",
    "    fig.add_subplot(212,sharex=ax1)\n",
    "    display_photo_no(image_id)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-165fdac7fe5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhaziness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_haziness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-35f39c0f0bdf>\u001b[0m in \u001b[0;36mcalculate_haziness\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     img = cv2.imread(path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#image to gray scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_intensity_of_atmospheric_light\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7a2f05acc6af>\u001b[0m in \u001b[0;36mfind_intensity_of_atmospheric_light\u001b[0;34m(img, gray)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoplist\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# create 65 different channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintensity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "haziness = list(map(calculate_haziness,X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('top picture is haze-free image, bottom one is the original picture')\n",
    "compare_photos(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression \n",
    "- Distiguish haze | clear label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haziness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Neural Network vanilla model\n",
    "- Importing the Keras libraries and packages\n",
    "- Sequential:<br> initialise model as a sequential network. There are two basic ways of initialising a neural network, either by a sequence of layers or as a graph\n",
    "\n",
    "\n",
    "\n",
    "#### 1.2 Model Work Flow\n",
    "1. **Conv2D** \n",
    "    - Images => 2 D arrays\n",
    "    - Videos => Convolution 3-D \n",
    "    \n",
    "    \n",
    "2. **MaxPooling2D**:<br> The primary aim of a pooling operation is to reduce the size of the images. Different types of pooling operations like Min Pooling, Mean Pooling, etc. Here in MaxPooling we need the maximum value pixel from the respective region of interest.\n",
    "\n",
    "\n",
    "3. **Flatten**:<br> Flattening is the process of converting all the resultant 2 dimensional arrays into a continuous vector.\n",
    "\n",
    "\n",
    "4. **Dense** \n",
    "    - units: no nodes in the hidden layer\n",
    "5. **compile**\n",
    "    - Optimizer:  stochastic gradient descent algorithm\n",
    "    - Loss: loss function\n",
    "    - Metrics: performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout,BatchNormalization\n",
    "from keras.initializers import glorot_normal, RandomNormal, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_layers2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3),activation = 'relu', input_shape = (256, 256, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(3, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(17))\n",
    "    model.add(Activation('sigmoid'))\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true,y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true,y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "    \n",
    "def F2_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return (1+4)*precision*recall/(4*precision+recall)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = build_layers2()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
    "                  metrics = ['accuracy',F2_score])\n",
    "    return model\n",
    "\n",
    "def train_model():\n",
    "    model = get_model()\n",
    "    model.fit(X_train, y_train, epochs=2, batch_size=50)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss: %.3f  accuracy: %.3f F2 score: %.3f.' %(score[0],score[1],score[2]))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model()\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = train_model()\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Implementation\n",
    "Build different models and test\n",
    "\n",
    "F2 | prec  |  recall\n",
    "_________________________\n",
    "0.45 | 0.00 | 0.00 | model 1 - single layer \n",
    "\n",
    "0.70 | 0.47 | 0.75 | model 2 Test F2: 0.754 - multi layers\n",
    "\n",
    "0.00 | 0.00 | 0.00 | model 3 - haze free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_labels(model):\n",
    "    N = 5000\n",
    "    y_pred = model.predict(X_train[0:N])\n",
    "    primary_train = y_pred[:,2]\n",
    "    primary_test = y_train['clear'][0:N].values\n",
    "    plt.scatter(primary_train,primary_test)\n",
    "    plt.show()\n",
    "predict_test_labels(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix\n",
    "version 1 - single layer\n",
    "```python\n",
    "def build_layers():\n",
    "    \"\"\"32 filters of size 12x12\n",
    "        input image size 256 x 256, 3 for RGB\n",
    "    \"\"\"\n",
    "    no_features = 17\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(12,12), activation = 'relu',input_shape = (256, 256, 3)))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = no_features, activation = 'sigmoid'))\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
